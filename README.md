Discogs Lakehouse (Local) ‚Äî Run-based, Reproducible Pipeline

This project implements a local-first Discogs lakehouse with run-based versioning, immutable snapshots, and atomic promotion of validated data.

The system is designed to behave like a real production data platform, while remaining fully reproducible on a laptop.

================================================================================


Project structure

The architecture is intentionally split into two repositories, each with a clear responsibility.


1) Infrastructure layer

Trino + Hive Metastore + external table bootstrap

Repo:
üëâ https://github.com/PabloPablo666/trino-hive-setup

Responsibilities:
	‚Ä¢	Trino compute engine (stateless)
	‚Ä¢	Hive Metastore backed by Postgres
	‚Ä¢	External table registration
	‚Ä¢	Stable SQL contract for consumers

This layer can be destroyed and recreated at any time without touching the data.


2) Pipeline & validation layer

Discogs ingestion, transformations, tests, orchestration

Repo:
üëâ https://github.com/PabloPablo666/discogs_tools_refactor

Responsibilities:
	‚Ä¢	Download Discogs dumps
	‚Ä¢	Stream-parse large XML files
	‚Ä¢	Write typed Parquet datasets
	‚Ä¢	Build analytical warehouse tables
	‚Ä¢	Run validation tests
	‚Ä¢	Produce sanity reports
	‚Ä¢	Promote validated data atomically

This repo owns the data lifecycle.

================================================================================


Core design principles


‚úÖ Run-based architecture

Every pipeline execution creates an immutable snapshot:
hive-data/
‚îî‚îÄ‚îÄ _runs/
    ‚îî‚îÄ‚îÄ YYYYMMDD_HHMMSS/

Each run contains:
‚Ä¢	base typed datasets
‚Ä¢	derived warehouse datasets
‚Ä¢	reports and logs

Nothing is overwritten.
Every run is fully reproducible.


‚úÖ Active pointer (publish layer)

Consumers never read from _runs.

Instead, a single symbolic link is used:

hive-data/active -> _runs/20260117_192144

Promotion is performed by switching this pointer atomically.

Benefits:
	‚Ä¢	zero-downtime data publishing
	‚Ä¢	instant rollback
	‚Ä¢	stable table locations in Trino


‚úÖ Immutable data, mutable pointer

Data is immutable.
Only the pointer moves.

This is the same principle used by:
	‚Ä¢	data warehouses
	‚Ä¢	lakehouse systems
	‚Ä¢	versioned datasets in production

================================================================================


Data layout

Physical storage (run snapshot)
hive-data/
‚îî‚îÄ‚îÄ _runs/
    ‚îî‚îÄ‚îÄ <run_id>/
        ‚îú‚îÄ‚îÄ artists_v1_typed/
        ‚îú‚îÄ‚îÄ artist_aliases_v1_typed/
        ‚îú‚îÄ‚îÄ artist_memberships_v1_typed/
        ‚îú‚îÄ‚îÄ masters_v1_typed/
        ‚îú‚îÄ‚îÄ releases_v6/
        ‚îú‚îÄ‚îÄ labels_v10/
        ‚îú‚îÄ‚îÄ collection/
        ‚îú‚îÄ‚îÄ warehouse_discogs/
        ‚îî‚îÄ‚îÄ _reports/

Each directory contains Parquet files only.

================================================================================


Logical access (Trino)

Trino external tables always point to:       
file:/data/hive-data/active/...

As a result:
	‚Ä¢	SQL never changes
	‚Ä¢	dashboards never change
	‚Ä¢	notebooks never change

Only the underlying run changes after promotion.

================================================================================


Pipeline stages

The pipeline is orchestrated with Digdag and follows a strict lifecycle.

1) Preflight
	‚Ä¢	validate environment variables
	‚Ä¢	verify dump availability
	‚Ä¢	compute run_id


2) Download (optional)
	‚Ä¢	download Discogs dumps by month
	‚Ä¢	idempotent (skips existing files)


3) Ingest
	‚Ä¢	streaming XML parsing (no full-file loading)
	‚Ä¢	typed canonical datasets written as Parquet
	‚Ä¢	one dataset per entity

Examples:
	‚Ä¢	artists_v1_typed
	‚Ä¢	labels_v10
	‚Ä¢	masters_v1_typed
	‚Ä¢	releases_v6


4) Build warehouse

Derived analytical datasets are generated:
	‚Ä¢	artist_name_map_v1
	‚Ä¢	release_artists_v1
	‚Ä¢	release_label_xref_v1
	‚Ä¢	label_release_counts_v1
	‚Ä¢	genre/style cross-reference tables

These tables are optimized for analytics, not raw storage.


5) Run-level parquet sanity checks

Executed on the current run directory before promotion.

Examples:
	‚Ä¢	required datasets exist
	‚Ä¢	directories not empty
	‚Ä¢	structural sanity

If these fail, the run is aborted.


6) Promote

If all checks pass:

active -> _runs/<run_id>

The previous active pointer is backed up automatically:

active__prev_<timestamp>
Rollback is a single filesystem operation.


7) Post-promotion Trino sanity report

After promotion, Trino is used to validate real query behavior.

Checks include:
	‚Ä¢	row counts
	‚Ä¢	null ratios
	‚Ä¢	orphan foreign keys
	‚Ä¢	duplicate keys
	‚Ä¢	cross-table integrity

Results are exported as CSV.
_runs/<run_id>/_reports/trino_sanity_active_<timestamp>.csv

This creates a permanent audit trail.

================================================================================


Why this design matters

‚úî Reproducibility

Any historical run can be re-queried exactly as it was produced.

‚úî Safe experimentation

New dumps can be ingested without touching production data.

‚úî Atomic publishing

Consumers see either old data or new data, never partial states.

‚úî Rollback

One symlink switch.

‚úî Auditable

Every run produces structured validation reports.

‚úî Infrastructure independence

Trino and Hive can be rebuilt freely.

================================================================================

What this project is not
	‚Ä¢	not a toy ETL
	‚Ä¢	not a one-off parser
	‚Ä¢	not overwrite-based ingestion
	‚Ä¢	not ‚Äújust some Parquet files‚Äù

It behaves like a real lakehouse pipeline.

================================================================================


Legal note

Discogs data is subject to Discogs licensing terms.

This project:
	‚Ä¢	does not ship Discogs datasets
	‚Ä¢	does not redistribute dumps
	‚Ä¢	focuses purely on infrastructure and data engineering patterns
